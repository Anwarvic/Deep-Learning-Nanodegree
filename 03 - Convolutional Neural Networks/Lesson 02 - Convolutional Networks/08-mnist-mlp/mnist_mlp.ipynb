{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Intelligence Nanodegree\n",
    "\n",
    "## Convolutional Neural Networks\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, we train an MLP to classify images from the MNIST database.\n",
    "\n",
    "### 1. Load MNIST Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MNIST database has a training set of 60000 examples.\n",
      "The MNIST database has a test set of 10000 examples.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# use Keras to import pre-shuffled MNIST database\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(\"The MNIST database has a training set of %d examples.\" % len(X_train))\n",
    "print(\"The MNIST database has a test set of %d examples.\" % len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Visualize the First Six Training Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "# plot first six training images\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "for i in range(6):\n",
    "    ax = fig.add_subplot(1, 6, i+1, xticks=[], yticks=[])\n",
    "    ax.imshow(X_train[i], cmap='gray')\n",
    "    ax.set_title(str(y_train[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. View an Image in More Detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_input(img, ax):\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    width, height = img.shape\n",
    "    thresh = img.max()/2.5\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            ax.annotate(str(round(img[x][y],2)), xy=(y,x),\n",
    "                        horizontalalignment='center',\n",
    "                        verticalalignment='center',\n",
    "                        color='white' if img[x][y]<thresh else 'black')\n",
    "\n",
    "fig = plt.figure(figsize = (12,12)) \n",
    "ax = fig.add_subplot(111)\n",
    "visualize_input(X_train[0], ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Rescale the Images by Dividing Every Pixel in Every Image by 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rescale [0,255] --> [0,1]\n",
    "X_train = X_train.astype('float32')/255\n",
    "X_test = X_test.astype('float32')/255 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Encode Categorical Integer Labels Using a One-Hot Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integer-valued labels:\n",
      "[5 0 4 1 9 2 1 3 1 4]\n",
      "One-hot labels:\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import utils\n",
    "\n",
    "# print first ten (integer-valued) training labels\n",
    "print('Integer-valued labels:')\n",
    "print(y_train[:10])\n",
    "\n",
    "# one-hot encode the labels\n",
    "y_train = utils.to_categorical(y_train, 10)\n",
    "y_test = utils.to_categorical(y_test, 10)\n",
    "\n",
    "# print first ten (one-hot) training labels\n",
    "print('One-hot labels:')\n",
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Define the Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\anwar\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\anwar\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "\n",
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=X_train.shape[1:]))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(rate=0.8)) #keep_prob=0.2\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(rate=0.8)) #keep_prob=0.2\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Calculate the Classification Accuracy on the Test Set (Before Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 10.4100%\n"
     ]
    }
   ],
   "source": [
    "# evaluate test accuracy\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "# print test accuracy\n",
    "print('Test accuracy: %.4f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "WARNING:tensorflow:From C:\\Users\\anwar\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "47744/48000 [============================>.] - ETA: 0s - loss: 13.8809 - acc: 0.1363\n",
      "Epoch 00001: val_loss improved from inf to 14.37177, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 20s 408us/sample - loss: 13.8787 - acc: 0.1364 - val_loss: 14.3718 - val_acc: 0.1079\n",
      "Epoch 2/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 13.4275 - acc: 0.1654\n",
      "Epoch 00002: val_loss improved from 14.37177 to 11.60681, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 17s 353us/sample - loss: 13.4259 - acc: 0.1655 - val_loss: 11.6068 - val_acc: 0.2718\n",
      "Epoch 3/10\n",
      "47744/48000 [============================>.] - ETA: 0s - loss: 13.0083 - acc: 0.1914\n",
      "Epoch 00003: val_loss improved from 11.60681 to 11.52837, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 16s 335us/sample - loss: 13.0075 - acc: 0.1914 - val_loss: 11.5284 - val_acc: 0.2820\n",
      "Epoch 4/10\n",
      "47744/48000 [============================>.] - ETA: 0s - loss: 12.5487 - acc: 0.2201\n",
      "Epoch 00004: val_loss improved from 11.52837 to 8.66533, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 16s 336us/sample - loss: 12.5499 - acc: 0.2200 - val_loss: 8.6653 - val_acc: 0.4604\n",
      "Epoch 5/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 12.3196 - acc: 0.2348\n",
      "Epoch 00005: val_loss did not improve from 8.66533\n",
      "48000/48000 [==============================] - 16s 336us/sample - loss: 12.3190 - acc: 0.2348 - val_loss: 10.0330 - val_acc: 0.3767\n",
      "Epoch 6/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 11.9733 - acc: 0.2559\n",
      "Epoch 00006: val_loss did not improve from 8.66533\n",
      "48000/48000 [==============================] - 17s 364us/sample - loss: 11.9699 - acc: 0.2561 - val_loss: 9.7913 - val_acc: 0.3909\n",
      "Epoch 7/10\n",
      "47744/48000 [============================>.] - ETA: 0s - loss: 11.5195 - acc: 0.2843\n",
      "Epoch 00007: val_loss did not improve from 8.66533\n",
      "48000/48000 [==============================] - 17s 355us/sample - loss: 11.5212 - acc: 0.2842 - val_loss: 9.3186 - val_acc: 0.4207\n",
      "Epoch 8/10\n",
      "47744/48000 [============================>.] - ETA: 0s - loss: 11.1635 - acc: 0.3064\n",
      "Epoch 00008: val_loss did not improve from 8.66533\n",
      "48000/48000 [==============================] - 17s 357us/sample - loss: 11.1644 - acc: 0.3063 - val_loss: 8.8056 - val_acc: 0.4524\n",
      "Epoch 9/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 10.8015 - acc: 0.3290\n",
      "Epoch 00009: val_loss improved from 8.66533 to 8.54699, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 17s 360us/sample - loss: 10.8022 - acc: 0.3290 - val_loss: 8.5470 - val_acc: 0.4692\n",
      "Epoch 10/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 10.4300 - acc: 0.3519\n",
      "Epoch 00010: val_loss improved from 8.54699 to 8.21425, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 17s 364us/sample - loss: 10.4294 - acc: 0.3519 - val_loss: 8.2142 - val_acc: 0.4900\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint   \n",
    "\n",
    "# train the model\n",
    "checkpointer = ModelCheckpoint(filepath='mnist.model.my_best.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "hist = model.fit(X_train, y_train, batch_size=128, epochs=10,\n",
    "          validation_split=0.2, callbacks=[checkpointer],\n",
    "          verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Calculate the Classification Accuracy on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 96.5000%\n"
     ]
    }
   ],
   "source": [
    "# evaluate test accuracy\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "# print test accuracy\n",
    "print('Test accuracy: %.4f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try-outs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Number of hidden nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.6184 - acc: 0.8049\n",
      "Epoch 00001: val_loss improved from inf to 0.18904, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 38s 802us/sample - loss: 0.6176 - acc: 0.8051 - val_loss: 0.1890 - val_acc: 0.9464\n",
      "Epoch 2/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.3326 - acc: 0.9077\n",
      "Epoch 00002: val_loss improved from 0.18904 to 0.16998, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 37s 776us/sample - loss: 0.3322 - acc: 0.9077 - val_loss: 0.1700 - val_acc: 0.9560\n",
      "Epoch 3/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.3011 - acc: 0.9226\n",
      "Epoch 00003: val_loss improved from 0.16998 to 0.15514, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 37s 765us/sample - loss: 0.3019 - acc: 0.9225 - val_loss: 0.1551 - val_acc: 0.9617\n",
      "Epoch 4/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.2821 - acc: 0.9317\n",
      "Epoch 00004: val_loss did not improve from 0.15514\n",
      "48000/48000 [==============================] - 38s 797us/sample - loss: 0.2822 - acc: 0.9317 - val_loss: 0.1588 - val_acc: 0.9634\n",
      "Epoch 5/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.2707 - acc: 0.9361\n",
      "Epoch 00005: val_loss improved from 0.15514 to 0.14810, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 41s 850us/sample - loss: 0.2704 - acc: 0.9362 - val_loss: 0.1481 - val_acc: 0.9664\n",
      "Epoch 6/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.2599 - acc: 0.9400\n",
      "Epoch 00006: val_loss did not improve from 0.14810\n",
      "48000/48000 [==============================] - 38s 797us/sample - loss: 0.2602 - acc: 0.9399 - val_loss: 0.1504 - val_acc: 0.9670\n",
      "Epoch 7/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.2598 - acc: 0.9409\n",
      "Epoch 00007: val_loss did not improve from 0.14810\n",
      "48000/48000 [==============================] - 38s 784us/sample - loss: 0.2603 - acc: 0.9409 - val_loss: 0.1573 - val_acc: 0.9670\n",
      "Epoch 8/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.2580 - acc: 0.9446\n",
      "Epoch 00008: val_loss did not improve from 0.14810\n",
      "48000/48000 [==============================] - 38s 785us/sample - loss: 0.2580 - acc: 0.9446 - val_loss: 0.1511 - val_acc: 0.9704\n",
      "Epoch 9/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.2565 - acc: 0.9455\n",
      "Epoch 00009: val_loss did not improve from 0.14810\n",
      "48000/48000 [==============================] - 38s 787us/sample - loss: 0.2567 - acc: 0.9454 - val_loss: 0.1544 - val_acc: 0.9705\n",
      "Epoch 10/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.2509 - acc: 0.9474\n",
      "Epoch 00010: val_loss did not improve from 0.14810\n",
      "48000/48000 [==============================] - 38s 797us/sample - loss: 0.2511 - acc: 0.9473 - val_loss: 0.1554 - val_acc: 0.9705\n",
      "Test accuracy: 97.0300%\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=X_train.shape[1:]))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(rate=0.8)) #keep_prob=0.2\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(rate=0.8)) #keep_prob=0.2\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "checkpointer = ModelCheckpoint(filepath='mnist.model.my_best.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "hist = model.fit(X_train, y_train, batch_size=128, epochs=10,\n",
    "          validation_split=0.2, callbacks=[checkpointer],\n",
    "          verbose=1, shuffle=True)\n",
    "\n",
    "# evaluate test accuracy\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "print('Test accuracy: %.4f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Decrease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "47616/48000 [============================>.] - ETA: 0s - loss: 1.1708 - acc: 0.6060\n",
      "Epoch 00001: val_loss improved from inf to 0.32233, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 11s 234us/sample - loss: 1.1672 - acc: 0.6074 - val_loss: 0.3223 - val_acc: 0.9159\n",
      "Epoch 2/10\n",
      "47744/48000 [============================>.] - ETA: 0s - loss: 0.6011 - acc: 0.8283\n",
      "Epoch 00002: val_loss improved from 0.32233 to 0.26080, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 9s 178us/sample - loss: 0.6000 - acc: 0.8285 - val_loss: 0.2608 - val_acc: 0.9305\n",
      "Epoch 3/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.5133 - acc: 0.8612\n",
      "Epoch 00003: val_loss improved from 0.26080 to 0.24310, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 8s 176us/sample - loss: 0.5131 - acc: 0.8613 - val_loss: 0.2431 - val_acc: 0.9379\n",
      "Epoch 4/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.4883 - acc: 0.8772\n",
      "Epoch 00004: val_loss improved from 0.24310 to 0.23432, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 9s 181us/sample - loss: 0.4879 - acc: 0.8771 - val_loss: 0.2343 - val_acc: 0.9439\n",
      "Epoch 5/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.4655 - acc: 0.8842\n",
      "Epoch 00005: val_loss improved from 0.23432 to 0.22992, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 10s 216us/sample - loss: 0.4656 - acc: 0.8842 - val_loss: 0.2299 - val_acc: 0.9463\n",
      "Epoch 6/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.4570 - acc: 0.8871\n",
      "Epoch 00006: val_loss improved from 0.22992 to 0.22562, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 11s 233us/sample - loss: 0.4576 - acc: 0.8870 - val_loss: 0.2256 - val_acc: 0.9494\n",
      "Epoch 7/10\n",
      "47744/48000 [============================>.] - ETA: 0s - loss: 0.4494 - acc: 0.8916\n",
      "Epoch 00007: val_loss improved from 0.22562 to 0.21992, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 12s 251us/sample - loss: 0.4497 - acc: 0.8916 - val_loss: 0.2199 - val_acc: 0.9503\n",
      "Epoch 8/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.4561 - acc: 0.8922\n",
      "Epoch 00008: val_loss did not improve from 0.21992\n",
      "48000/48000 [==============================] - 10s 211us/sample - loss: 0.4568 - acc: 0.8922 - val_loss: 0.2223 - val_acc: 0.9527\n",
      "Epoch 9/10\n",
      "47744/48000 [============================>.] - ETA: 0s - loss: 0.4434 - acc: 0.8955\n",
      "Epoch 00009: val_loss did not improve from 0.21992\n",
      "48000/48000 [==============================] - 13s 279us/sample - loss: 0.4439 - acc: 0.8953 - val_loss: 0.2310 - val_acc: 0.9529\n",
      "Epoch 10/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.4468 - acc: 0.8965\n",
      "Epoch 00010: val_loss did not improve from 0.21992\n",
      "48000/48000 [==============================] - 12s 249us/sample - loss: 0.4462 - acc: 0.8965 - val_loss: 0.2334 - val_acc: 0.9532\n",
      "Test accuracy: 94.8400%\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=X_train.shape[1:]))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(rate=0.8)) #keep_prob=0.2\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(rate=0.8)) #keep_prob=0.2\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "checkpointer = ModelCheckpoint(filepath='mnist.model.my_best.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "hist = model.fit(X_train, y_train, batch_size=128, epochs=10,\n",
    "          validation_split=0.2, callbacks=[checkpointer],\n",
    "          verbose=1, shuffle=True)\n",
    "\n",
    "# evaluate test accuracy\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "print('Test accuracy: %.4f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Number of hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 1.4414 - acc: 0.4992\n",
      "Epoch 00001: val_loss improved from inf to 0.40815, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 25s 525us/sample - loss: 1.4391 - acc: 0.5001 - val_loss: 0.4082 - val_acc: 0.9033\n",
      "Epoch 2/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.6726 - acc: 0.8099\n",
      "Epoch 00002: val_loss improved from 0.40815 to 0.29046, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 23s 475us/sample - loss: 0.6720 - acc: 0.8102 - val_loss: 0.2905 - val_acc: 0.9284\n",
      "Epoch 3/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.5623 - acc: 0.8594\n",
      "Epoch 00003: val_loss improved from 0.29046 to 0.25042, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 26s 533us/sample - loss: 0.5621 - acc: 0.8594 - val_loss: 0.2504 - val_acc: 0.9374\n",
      "Epoch 4/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.5239 - acc: 0.8767\n",
      "Epoch 00004: val_loss improved from 0.25042 to 0.23257, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 25s 511us/sample - loss: 0.5245 - acc: 0.8767 - val_loss: 0.2326 - val_acc: 0.9438\n",
      "Epoch 5/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.5195 - acc: 0.8858\n",
      "Epoch 00005: val_loss did not improve from 0.23257\n",
      "48000/48000 [==============================] - 27s 557us/sample - loss: 0.5196 - acc: 0.8857 - val_loss: 0.2441 - val_acc: 0.9461\n",
      "Epoch 6/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.4864 - acc: 0.8932\n",
      "Epoch 00006: val_loss did not improve from 0.23257\n",
      "48000/48000 [==============================] - 30s 620us/sample - loss: 0.4865 - acc: 0.8932 - val_loss: 0.2424 - val_acc: 0.9472\n",
      "Epoch 7/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.4978 - acc: 0.8957\n",
      "Epoch 00007: val_loss did not improve from 0.23257\n",
      "48000/48000 [==============================] - 30s 635us/sample - loss: 0.4972 - acc: 0.8959 - val_loss: 0.2438 - val_acc: 0.9477\n",
      "Epoch 8/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.4892 - acc: 0.8990\n",
      "Epoch 00008: val_loss did not improve from 0.23257\n",
      "48000/48000 [==============================] - 30s 619us/sample - loss: 0.4892 - acc: 0.8989 - val_loss: 0.2413 - val_acc: 0.9507\n",
      "Epoch 9/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.5011 - acc: 0.9015\n",
      "Epoch 00009: val_loss did not improve from 0.23257\n",
      "48000/48000 [==============================] - 29s 609us/sample - loss: 0.5009 - acc: 0.9015 - val_loss: 0.2613 - val_acc: 0.9505\n",
      "Epoch 10/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.4996 - acc: 0.9027\n",
      "Epoch 00010: val_loss did not improve from 0.23257\n",
      "48000/48000 [==============================] - 30s 627us/sample - loss: 0.4995 - acc: 0.9028 - val_loss: 0.2566 - val_acc: 0.9501\n",
      "Test accuracy: 94.7300%\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=X_train.shape[1:]))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(rate=0.8)) #keep_prob=0.2\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(rate=0.8)) #keep_prob=0.2\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(rate=0.8)) #keep_prob=0.2\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "checkpointer = ModelCheckpoint(filepath='mnist.model.my_best.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "hist = model.fit(X_train, y_train, batch_size=128, epochs=10,\n",
    "          validation_split=0.2, callbacks=[checkpointer],\n",
    "          verbose=1, shuffle=True)\n",
    "\n",
    "# evaluate test accuracy\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "print('Test accuracy: %.4f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Decrease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.5201 - acc: 0.8420\n",
      "Epoch 00001: val_loss improved from inf to 0.20916, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 15s 310us/sample - loss: 0.5200 - acc: 0.8420 - val_loss: 0.2092 - val_acc: 0.9412\n",
      "Epoch 2/10\n",
      "47744/48000 [============================>.] - ETA: 0s - loss: 0.2969 - acc: 0.9125\n",
      "Epoch 00002: val_loss improved from 0.20916 to 0.16469, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 12s 243us/sample - loss: 0.2968 - acc: 0.9125 - val_loss: 0.1647 - val_acc: 0.9546\n",
      "Epoch 3/10\n",
      "47744/48000 [============================>.] - ETA: 0s - loss: 0.2562 - acc: 0.9260\n",
      "Epoch 00003: val_loss improved from 0.16469 to 0.14222, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 11s 230us/sample - loss: 0.2562 - acc: 0.9259 - val_loss: 0.1422 - val_acc: 0.9589\n",
      "Epoch 4/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.2263 - acc: 0.9344\n",
      "Epoch 00004: val_loss improved from 0.14222 to 0.13214, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 11s 230us/sample - loss: 0.2261 - acc: 0.9345 - val_loss: 0.1321 - val_acc: 0.9641\n",
      "Epoch 5/10\n",
      "47616/48000 [============================>.] - ETA: 0s - loss: 0.2118 - acc: 0.9389\n",
      "Epoch 00005: val_loss improved from 0.13214 to 0.12937, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 11s 220us/sample - loss: 0.2114 - acc: 0.9390 - val_loss: 0.1294 - val_acc: 0.9647\n",
      "Epoch 6/10\n",
      "47744/48000 [============================>.] - ETA: 0s - loss: 0.2041 - acc: 0.9443\n",
      "Epoch 00006: val_loss improved from 0.12937 to 0.12332, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 12s 246us/sample - loss: 0.2042 - acc: 0.9442 - val_loss: 0.1233 - val_acc: 0.9676\n",
      "Epoch 7/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.1969 - acc: 0.9459\n",
      "Epoch 00007: val_loss improved from 0.12332 to 0.12007, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 11s 229us/sample - loss: 0.1972 - acc: 0.9459 - val_loss: 0.1201 - val_acc: 0.9691\n",
      "Epoch 8/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.1859 - acc: 0.9497\n",
      "Epoch 00008: val_loss did not improve from 0.12007\n",
      "48000/48000 [==============================] - 11s 230us/sample - loss: 0.1858 - acc: 0.9497 - val_loss: 0.1209 - val_acc: 0.9703\n",
      "Epoch 9/10\n",
      "47744/48000 [============================>.] - ETA: 0s - loss: 0.1828 - acc: 0.9495\n",
      "Epoch 00009: val_loss did not improve from 0.12007\n",
      "48000/48000 [==============================] - 11s 230us/sample - loss: 0.1831 - acc: 0.9496 - val_loss: 0.1203 - val_acc: 0.9694\n",
      "Epoch 10/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.1811 - acc: 0.9520\n",
      "Epoch 00010: val_loss improved from 0.12007 to 0.11661, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 11s 235us/sample - loss: 0.1811 - acc: 0.9520 - val_loss: 0.1166 - val_acc: 0.9708\n",
      "Test accuracy: 97.1700%\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=X_train.shape[1:]))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(rate=0.8)) #keep_prob=0.2\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "checkpointer = ModelCheckpoint(filepath='mnist.model.my_best.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "hist = model.fit(X_train, y_train, batch_size=128, epochs=10,\n",
    "          validation_split=0.2, callbacks=[checkpointer],\n",
    "          verbose=1, shuffle=True)\n",
    "\n",
    "# evaluate test accuracy\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "print('Test accuracy: %.4f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Remove Dropouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.2488 - acc: 0.9241\n",
      "Epoch 00001: val_loss improved from inf to 0.11801, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 17s 352us/sample - loss: 0.2482 - acc: 0.9243 - val_loss: 0.1180 - val_acc: 0.9646\n",
      "Epoch 2/10\n",
      "47744/48000 [============================>.] - ETA: 0s - loss: 0.0895 - acc: 0.9712\n",
      "Epoch 00002: val_loss improved from 0.11801 to 0.10506, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 15s 317us/sample - loss: 0.0895 - acc: 0.9712 - val_loss: 0.1051 - val_acc: 0.9700\n",
      "Epoch 3/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.0563 - acc: 0.9827\n",
      "Epoch 00003: val_loss improved from 0.10506 to 0.09948, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 16s 335us/sample - loss: 0.0563 - acc: 0.9827 - val_loss: 0.0995 - val_acc: 0.9740\n",
      "Epoch 4/10\n",
      "47744/48000 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9870\n",
      "Epoch 00004: val_loss did not improve from 0.09948\n",
      "48000/48000 [==============================] - 18s 382us/sample - loss: 0.0403 - acc: 0.9870 - val_loss: 0.1066 - val_acc: 0.9728\n",
      "Epoch 5/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.0301 - acc: 0.9908\n",
      "Epoch 00005: val_loss did not improve from 0.09948\n",
      "48000/48000 [==============================] - 20s 412us/sample - loss: 0.0301 - acc: 0.9908 - val_loss: 0.1192 - val_acc: 0.9734\n",
      "Epoch 6/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9926\n",
      "Epoch 00006: val_loss did not improve from 0.09948\n",
      "48000/48000 [==============================] - 20s 407us/sample - loss: 0.0247 - acc: 0.9926 - val_loss: 0.1114 - val_acc: 0.9765\n",
      "Epoch 7/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9944\n",
      "Epoch 00007: val_loss did not improve from 0.09948\n",
      "48000/48000 [==============================] - 21s 436us/sample - loss: 0.0178 - acc: 0.9944 - val_loss: 0.1260 - val_acc: 0.9756\n",
      "Epoch 8/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.0152 - acc: 0.9950\n",
      "Epoch 00008: val_loss did not improve from 0.09948\n",
      "48000/48000 [==============================] - 24s 498us/sample - loss: 0.0152 - acc: 0.9951 - val_loss: 0.1129 - val_acc: 0.9789\n",
      "Epoch 9/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9956\n",
      "Epoch 00009: val_loss did not improve from 0.09948\n",
      "48000/48000 [==============================] - 24s 492us/sample - loss: 0.0135 - acc: 0.9956 - val_loss: 0.1407 - val_acc: 0.9769\n",
      "Epoch 10/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.0099 - acc: 0.9968\n",
      "Epoch 00010: val_loss did not improve from 0.09948\n",
      "48000/48000 [==============================] - 16s 333us/sample - loss: 0.0101 - acc: 0.9967 - val_loss: 0.1614 - val_acc: 0.9740\n",
      "Test accuracy: 97.5600%\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=X_train.shape[1:]))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "checkpointer = ModelCheckpoint(filepath='mnist.model.my_best.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "hist = model.fit(X_train, y_train, batch_size=128, epochs=10,\n",
    "          validation_split=0.2, callbacks=[checkpointer],\n",
    "          verbose=1, shuffle=True)\n",
    "\n",
    "# evaluate test accuracy\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "print('Test accuracy: %.4f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Remove ReLU activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "47744/48000 [============================>.] - ETA: 0s - loss: 0.9919 - acc: 0.7353\n",
      "Epoch 00001: val_loss improved from inf to 0.34443, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 20s 425us/sample - loss: 0.9901 - acc: 0.7359 - val_loss: 0.3444 - val_acc: 0.9136\n",
      "Epoch 2/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.6725 - acc: 0.8237\n",
      "Epoch 00002: val_loss improved from 0.34443 to 0.33765, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 23s 481us/sample - loss: 0.6724 - acc: 0.8236 - val_loss: 0.3376 - val_acc: 0.9087\n",
      "Epoch 3/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.5905 - acc: 0.8396\n",
      "Epoch 00003: val_loss improved from 0.33765 to 0.31055, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 30s 622us/sample - loss: 0.5906 - acc: 0.8397 - val_loss: 0.3106 - val_acc: 0.9145\n",
      "Epoch 4/10\n",
      "47744/48000 [============================>.] - ETA: 0s - loss: 0.5462 - acc: 0.8493\n",
      "Epoch 00004: val_loss did not improve from 0.31055\n",
      "48000/48000 [==============================] - 27s 565us/sample - loss: 0.5456 - acc: 0.8496 - val_loss: 0.3154 - val_acc: 0.9169\n",
      "Epoch 5/10\n",
      "47744/48000 [============================>.] - ETA: 0s - loss: 0.5390 - acc: 0.8498\n",
      "Epoch 00005: val_loss improved from 0.31055 to 0.30765, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 22s 457us/sample - loss: 0.5389 - acc: 0.8498 - val_loss: 0.3076 - val_acc: 0.9151\n",
      "Epoch 6/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.5302 - acc: 0.8545\n",
      "Epoch 00006: val_loss improved from 0.30765 to 0.29939, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 16s 334us/sample - loss: 0.5304 - acc: 0.8545 - val_loss: 0.2994 - val_acc: 0.9189\n",
      "Epoch 7/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.5217 - acc: 0.8559\n",
      "Epoch 00007: val_loss improved from 0.29939 to 0.29561, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 16s 329us/sample - loss: 0.5214 - acc: 0.8560 - val_loss: 0.2956 - val_acc: 0.9189\n",
      "Epoch 8/10\n",
      "47744/48000 [============================>.] - ETA: 0s - loss: 0.5233 - acc: 0.8564\n",
      "Epoch 00008: val_loss did not improve from 0.29561\n",
      "48000/48000 [==============================] - 16s 327us/sample - loss: 0.5238 - acc: 0.8563 - val_loss: 0.3038 - val_acc: 0.9175\n",
      "Epoch 9/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.5282 - acc: 0.8554\n",
      "Epoch 00009: val_loss did not improve from 0.29561\n",
      "48000/48000 [==============================] - 18s 371us/sample - loss: 0.5280 - acc: 0.8555 - val_loss: 0.3064 - val_acc: 0.9171\n",
      "Epoch 10/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.5283 - acc: 0.8560\n",
      "Epoch 00010: val_loss did not improve from 0.29561\n",
      "48000/48000 [==============================] - 23s 481us/sample - loss: 0.5282 - acc: 0.8560 - val_loss: 0.3058 - val_acc: 0.9176\n",
      "Test accuracy: 91.5800%\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=X_train.shape[1:]))\n",
    "model.add(Dense(512))\n",
    "model.add(Dropout(rate=0.8)) #keep_prob=0.2\n",
    "model.add(Dense(512))\n",
    "model.add(Dropout(rate=0.8)) #keep_prob=0.2\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "checkpointer = ModelCheckpoint(filepath='mnist.model.my_best.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "hist = model.fit(X_train, y_train, batch_size=128, epochs=10,\n",
    "          validation_split=0.2, callbacks=[checkpointer],\n",
    "          verbose=1, shuffle=True)\n",
    "\n",
    "# evaluate test accuracy\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "print('Test accuracy: %.4f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Try different Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.8799 - acc: 0.7131\n",
      "Epoch 00001: val_loss improved from inf to 0.24976, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 26s 542us/sample - loss: 0.8788 - acc: 0.7136 - val_loss: 0.2498 - val_acc: 0.9281\n",
      "Epoch 2/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.4345 - acc: 0.8706\n",
      "Epoch 00002: val_loss improved from 0.24976 to 0.18561, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 27s 554us/sample - loss: 0.4344 - acc: 0.8707 - val_loss: 0.1856 - val_acc: 0.9484\n",
      "Epoch 3/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.3664 - acc: 0.8947\n",
      "Epoch 00003: val_loss improved from 0.18561 to 0.16353, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 23s 484us/sample - loss: 0.3658 - acc: 0.8948 - val_loss: 0.1635 - val_acc: 0.9538\n",
      "Epoch 4/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.3226 - acc: 0.9083\n",
      "Epoch 00004: val_loss improved from 0.16353 to 0.14379, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 21s 448us/sample - loss: 0.3222 - acc: 0.9083 - val_loss: 0.1438 - val_acc: 0.9585\n",
      "Epoch 5/10\n",
      "47744/48000 [============================>.] - ETA: 0s - loss: 0.3009 - acc: 0.9129\n",
      "Epoch 00005: val_loss improved from 0.14379 to 0.13804, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 23s 488us/sample - loss: 0.3008 - acc: 0.9129 - val_loss: 0.1380 - val_acc: 0.9610\n",
      "Epoch 6/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.2830 - acc: 0.9196\n",
      "Epoch 00006: val_loss improved from 0.13804 to 0.13266, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 24s 500us/sample - loss: 0.2829 - acc: 0.9195 - val_loss: 0.1327 - val_acc: 0.9633\n",
      "Epoch 7/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.2669 - acc: 0.9236\n",
      "Epoch 00007: val_loss improved from 0.13266 to 0.12773, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 22s 465us/sample - loss: 0.2670 - acc: 0.9235 - val_loss: 0.1277 - val_acc: 0.9639\n",
      "Epoch 8/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.2572 - acc: 0.9265\n",
      "Epoch 00008: val_loss improved from 0.12773 to 0.11664, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 24s 508us/sample - loss: 0.2571 - acc: 0.9266 - val_loss: 0.1166 - val_acc: 0.9668\n",
      "Epoch 9/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.2471 - acc: 0.9294\n",
      "Epoch 00009: val_loss did not improve from 0.11664\n",
      "48000/48000 [==============================] - 25s 511us/sample - loss: 0.2471 - acc: 0.9294 - val_loss: 0.1186 - val_acc: 0.9657\n",
      "Epoch 10/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.2461 - acc: 0.9288\n",
      "Epoch 00010: val_loss improved from 0.11664 to 0.11021, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 23s 484us/sample - loss: 0.2460 - acc: 0.9288 - val_loss: 0.1102 - val_acc: 0.9699\n",
      "Test accuracy: 96.8300%\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=X_train.shape[1:]))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(rate=0.8)) #keep_prob=0.2\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(rate=0.8)) #keep_prob=0.2\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "checkpointer = ModelCheckpoint(filepath='mnist.model.my_best.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "hist = model.fit(X_train, y_train, batch_size=128, epochs=10,\n",
    "          validation_split=0.2, callbacks=[checkpointer],\n",
    "          verbose=1, shuffle=True)\n",
    "\n",
    "# evaluate test accuracy\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "print('Test accuracy: %.4f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "47744/48000 [============================>.] - ETA: 0s - loss: 0.7898 - acc: 0.7495\n",
      "Epoch 00001: val_loss improved from inf to 0.26266, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 19s 396us/sample - loss: 0.7890 - acc: 0.7498 - val_loss: 0.2627 - val_acc: 0.9280\n",
      "Epoch 2/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.4644 - acc: 0.8638\n",
      "Epoch 00002: val_loss improved from 0.26266 to 0.21607, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 17s 346us/sample - loss: 0.4637 - acc: 0.8639 - val_loss: 0.2161 - val_acc: 0.9392\n",
      "Epoch 3/10\n",
      "47744/48000 [============================>.] - ETA: 0s - loss: 0.3898 - acc: 0.8899\n",
      "Epoch 00003: val_loss improved from 0.21607 to 0.19411, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 17s 360us/sample - loss: 0.3898 - acc: 0.8899 - val_loss: 0.1941 - val_acc: 0.9478\n",
      "Epoch 4/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.3575 - acc: 0.8980\n",
      "Epoch 00004: val_loss improved from 0.19411 to 0.18031, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 19s 387us/sample - loss: 0.3573 - acc: 0.8981 - val_loss: 0.1803 - val_acc: 0.9509\n",
      "Epoch 5/10\n",
      "47744/48000 [============================>.] - ETA: 0s - loss: 0.3282 - acc: 0.9075\n",
      "Epoch 00005: val_loss improved from 0.18031 to 0.16965, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 18s 378us/sample - loss: 0.3281 - acc: 0.9075 - val_loss: 0.1697 - val_acc: 0.9525\n",
      "Epoch 6/10\n",
      "47744/48000 [============================>.] - ETA: 0s - loss: 0.3109 - acc: 0.9132\n",
      "Epoch 00006: val_loss improved from 0.16965 to 0.15919, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 18s 371us/sample - loss: 0.3108 - acc: 0.9133 - val_loss: 0.1592 - val_acc: 0.9572\n",
      "Epoch 7/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.2973 - acc: 0.9167\n",
      "Epoch 00007: val_loss improved from 0.15919 to 0.15187, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 18s 373us/sample - loss: 0.2971 - acc: 0.9167 - val_loss: 0.1519 - val_acc: 0.9572\n",
      "Epoch 8/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.2845 - acc: 0.9191\n",
      "Epoch 00008: val_loss improved from 0.15187 to 0.14837, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 18s 367us/sample - loss: 0.2847 - acc: 0.9192 - val_loss: 0.1484 - val_acc: 0.9584\n",
      "Epoch 9/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.2730 - acc: 0.9238\n",
      "Epoch 00009: val_loss improved from 0.14837 to 0.14416, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 22s 463us/sample - loss: 0.2729 - acc: 0.9239 - val_loss: 0.1442 - val_acc: 0.9597\n",
      "Epoch 10/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.2622 - acc: 0.9266\n",
      "Epoch 00010: val_loss improved from 0.14416 to 0.14117, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 23s 487us/sample - loss: 0.2623 - acc: 0.9265 - val_loss: 0.1412 - val_acc: 0.9605\n",
      "Test accuracy: 95.8900%\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=X_train.shape[1:]))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(rate=0.8)) #keep_prob=0.2\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(rate=0.8)) #keep_prob=0.2\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adagrad', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "checkpointer = ModelCheckpoint(filepath='mnist.model.my_best.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "hist = model.fit(X_train, y_train, batch_size=128, epochs=10,\n",
    "          validation_split=0.2, callbacks=[checkpointer],\n",
    "          verbose=1, shuffle=True)\n",
    "\n",
    "# evaluate test accuracy\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "print('Test accuracy: %.4f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "47744/48000 [============================>.] - ETA: 0s - loss: 2.1706 - acc: 0.2385\n",
      "Epoch 00001: val_loss improved from inf to 1.51007, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 24s 505us/sample - loss: 2.1685 - acc: 0.2391 - val_loss: 1.5101 - val_acc: 0.7334\n",
      "Epoch 2/10\n",
      "47744/48000 [============================>.] - ETA: 0s - loss: 1.5563 - acc: 0.4682\n",
      "Epoch 00002: val_loss improved from 1.51007 to 0.91984, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 16s 325us/sample - loss: 1.5545 - acc: 0.4689 - val_loss: 0.9198 - val_acc: 0.8228\n",
      "Epoch 3/10\n",
      "47744/48000 [============================>.] - ETA: 0s - loss: 1.2009 - acc: 0.5900\n",
      "Epoch 00003: val_loss improved from 0.91984 to 0.66639, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 16s 325us/sample - loss: 1.2010 - acc: 0.5901 - val_loss: 0.6664 - val_acc: 0.8539\n",
      "Epoch 4/10\n",
      "47744/48000 [============================>.] - ETA: 0s - loss: 1.0138 - acc: 0.6585\n",
      "Epoch 00004: val_loss improved from 0.66639 to 0.54426, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 16s 341us/sample - loss: 1.0139 - acc: 0.6584 - val_loss: 0.5443 - val_acc: 0.8720\n",
      "Epoch 5/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.8874 - acc: 0.7062\n",
      "Epoch 00005: val_loss improved from 0.54426 to 0.47283, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 16s 332us/sample - loss: 0.8874 - acc: 0.7062 - val_loss: 0.4728 - val_acc: 0.8842\n",
      "Epoch 6/10\n",
      "47744/48000 [============================>.] - ETA: 0s - loss: 0.8033 - acc: 0.7395\n",
      "Epoch 00006: val_loss improved from 0.47283 to 0.42742, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 16s 337us/sample - loss: 0.8030 - acc: 0.7397 - val_loss: 0.4274 - val_acc: 0.8907\n",
      "Epoch 7/10\n",
      "47744/48000 [============================>.] - ETA: 0s - loss: 0.7501 - acc: 0.7584\n",
      "Epoch 00007: val_loss improved from 0.42742 to 0.39473, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 16s 336us/sample - loss: 0.7494 - acc: 0.7586 - val_loss: 0.3947 - val_acc: 0.8962\n",
      "Epoch 8/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.6982 - acc: 0.7803\n",
      "Epoch 00008: val_loss improved from 0.39473 to 0.36839, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 17s 360us/sample - loss: 0.6981 - acc: 0.7803 - val_loss: 0.3684 - val_acc: 0.9011\n",
      "Epoch 9/10\n",
      "47744/48000 [============================>.] - ETA: 0s - loss: 0.6539 - acc: 0.7956\n",
      "Epoch 00009: val_loss improved from 0.36839 to 0.34722, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 17s 345us/sample - loss: 0.6538 - acc: 0.7957 - val_loss: 0.3472 - val_acc: 0.9050\n",
      "Epoch 10/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.6248 - acc: 0.8050\n",
      "Epoch 00010: val_loss improved from 0.34722 to 0.33171, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 16s 334us/sample - loss: 0.6247 - acc: 0.8049 - val_loss: 0.3317 - val_acc: 0.9100\n",
      "Test accuracy: 90.7900%\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=X_train.shape[1:]))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(rate=0.8)) #keep_prob=0.2\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(rate=0.8)) #keep_prob=0.2\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='SGD', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "checkpointer = ModelCheckpoint(filepath='mnist.model.my_best.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "hist = model.fit(X_train, y_train, batch_size=128, epochs=10,\n",
    "          validation_split=0.2, callbacks=[checkpointer],\n",
    "          verbose=1, shuffle=True)\n",
    "\n",
    "# evaluate test accuracy\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "print('Test accuracy: %.4f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.9068 - acc: 0.7007\n",
      "Epoch 00001: val_loss improved from inf to 0.25930, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 17s 358us/sample - loss: 0.9057 - acc: 0.7011 - val_loss: 0.2593 - val_acc: 0.9234\n",
      "Epoch 2/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.4401 - acc: 0.8727\n",
      "Epoch 00002: val_loss improved from 0.25930 to 0.20156, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 15s 312us/sample - loss: 0.4395 - acc: 0.8729 - val_loss: 0.2016 - val_acc: 0.9420\n",
      "Epoch 3/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.3647 - acc: 0.8966\n",
      "Epoch 00003: val_loss improved from 0.20156 to 0.17409, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 18s 371us/sample - loss: 0.3650 - acc: 0.8966 - val_loss: 0.1741 - val_acc: 0.9523\n",
      "Epoch 4/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.3292 - acc: 0.9108\n",
      "Epoch 00004: val_loss improved from 0.17409 to 0.16225, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 15s 304us/sample - loss: 0.3288 - acc: 0.9109 - val_loss: 0.1622 - val_acc: 0.9579\n",
      "Epoch 5/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.3072 - acc: 0.9164\n",
      "Epoch 00005: val_loss improved from 0.16225 to 0.15469, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 15s 314us/sample - loss: 0.3070 - acc: 0.9164 - val_loss: 0.1547 - val_acc: 0.9587\n",
      "Epoch 6/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.2926 - acc: 0.9225\n",
      "Epoch 00006: val_loss improved from 0.15469 to 0.15442, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 14s 293us/sample - loss: 0.2931 - acc: 0.9224 - val_loss: 0.1544 - val_acc: 0.9606\n",
      "Epoch 7/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.2751 - acc: 0.9278\n",
      "Epoch 00007: val_loss improved from 0.15442 to 0.14827, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 17s 359us/sample - loss: 0.2755 - acc: 0.9278 - val_loss: 0.1483 - val_acc: 0.9632\n",
      "Epoch 8/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.2726 - acc: 0.9292\n",
      "Epoch 00008: val_loss improved from 0.14827 to 0.14341, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 15s 315us/sample - loss: 0.2726 - acc: 0.9292 - val_loss: 0.1434 - val_acc: 0.9655\n",
      "Epoch 9/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.2629 - acc: 0.9335\n",
      "Epoch 00009: val_loss did not improve from 0.14341\n",
      "48000/48000 [==============================] - 15s 302us/sample - loss: 0.2630 - acc: 0.9335 - val_loss: 0.1458 - val_acc: 0.9657\n",
      "Epoch 10/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.2588 - acc: 0.9352\n",
      "Epoch 00010: val_loss did not improve from 0.14341\n",
      "48000/48000 [==============================] - 15s 303us/sample - loss: 0.2596 - acc: 0.9351 - val_loss: 0.1481 - val_acc: 0.9669\n",
      "Test accuracy: 96.6700%\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=X_train.shape[1:]))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(rate=0.8)) #keep_prob=0.2\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(rate=0.8)) #keep_prob=0.2\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "checkpointer = ModelCheckpoint(filepath='mnist.model.my_best.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "hist = model.fit(X_train, y_train, batch_size=256, epochs=10,\n",
    "          validation_split=0.2, callbacks=[checkpointer],\n",
    "          verbose=1, shuffle=True)\n",
    "\n",
    "# evaluate test accuracy\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "print('Test accuracy: %.4f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Decrease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "47936/48000 [============================>.] - ETA: 0s - loss: 0.7966 - acc: 0.7485\n",
      "Epoch 00001: val_loss improved from inf to 0.24626, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 27s 573us/sample - loss: 0.7962 - acc: 0.7486 - val_loss: 0.2463 - val_acc: 0.9296\n",
      "Epoch 2/10\n",
      "47936/48000 [============================>.] - ETA: 0s - loss: 0.4577 - acc: 0.8822\n",
      "Epoch 00002: val_loss improved from 0.24626 to 0.22859, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 25s 516us/sample - loss: 0.4573 - acc: 0.8823 - val_loss: 0.2286 - val_acc: 0.9461\n",
      "Epoch 3/10\n",
      "47936/48000 [============================>.] - ETA: 0s - loss: 0.4256 - acc: 0.9019\n",
      "Epoch 00003: val_loss improved from 0.22859 to 0.22487, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 25s 519us/sample - loss: 0.4258 - acc: 0.9019 - val_loss: 0.2249 - val_acc: 0.9507\n",
      "Epoch 4/10\n",
      "47936/48000 [============================>.] - ETA: 0s - loss: 0.4215 - acc: 0.9080\n",
      "Epoch 00004: val_loss improved from 0.22487 to 0.21852, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 25s 516us/sample - loss: 0.4213 - acc: 0.9080 - val_loss: 0.2185 - val_acc: 0.9548\n",
      "Epoch 5/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.4200 - acc: 0.9130\n",
      "Epoch 00005: val_loss did not improve from 0.21852\n",
      "48000/48000 [==============================] - 25s 530us/sample - loss: 0.4197 - acc: 0.9132 - val_loss: 0.2204 - val_acc: 0.9582\n",
      "Epoch 6/10\n",
      "47936/48000 [============================>.] - ETA: 0s - loss: 0.4276 - acc: 0.9157\n",
      "Epoch 00006: val_loss did not improve from 0.21852\n",
      "48000/48000 [==============================] - 25s 521us/sample - loss: 0.4272 - acc: 0.9158 - val_loss: 0.2297 - val_acc: 0.9574\n",
      "Epoch 7/10\n",
      "47936/48000 [============================>.] - ETA: 0s - loss: 0.4302 - acc: 0.9171\n",
      "Epoch 00007: val_loss did not improve from 0.21852\n",
      "48000/48000 [==============================] - 28s 591us/sample - loss: 0.4298 - acc: 0.9171 - val_loss: 0.2262 - val_acc: 0.9610\n",
      "Epoch 8/10\n",
      "47936/48000 [============================>.] - ETA: 0s - loss: 0.4219 - acc: 0.9213\n",
      "Epoch 00008: val_loss did not improve from 0.21852\n",
      "48000/48000 [==============================] - 29s 611us/sample - loss: 0.4218 - acc: 0.9213 - val_loss: 0.2507 - val_acc: 0.9587\n",
      "Epoch 9/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.4251 - acc: 0.9220\n",
      "Epoch 00009: val_loss did not improve from 0.21852\n",
      "48000/48000 [==============================] - 25s 512us/sample - loss: 0.4250 - acc: 0.9221 - val_loss: 0.2366 - val_acc: 0.9620\n",
      "Epoch 10/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.4387 - acc: 0.9231\n",
      "Epoch 00010: val_loss did not improve from 0.21852\n",
      "48000/48000 [==============================] - 26s 542us/sample - loss: 0.4391 - acc: 0.9231 - val_loss: 0.2480 - val_acc: 0.9610\n",
      "Test accuracy: 95.9600%\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=X_train.shape[1:]))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(rate=0.8)) #keep_prob=0.2\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(rate=0.8)) #keep_prob=0.2\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "checkpointer = ModelCheckpoint(filepath='mnist.model.my_best.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "hist = model.fit(X_train, y_train, batch_size=64, epochs=10,\n",
    "          validation_split=0.2, callbacks=[checkpointer],\n",
    "          verbose=1, shuffle=True)\n",
    "\n",
    "# evaluate test accuracy\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "print('Test accuracy: %.4f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Remove image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "47744/48000 [============================>.] - ETA: 0s - loss: 14.4897 - acc: 0.1010\n",
      "Epoch 00001: val_loss improved from inf to 14.19376, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 19s 398us/sample - loss: 14.4896 - acc: 0.1010 - val_loss: 14.1938 - val_acc: 0.1192\n",
      "Epoch 2/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 14.4599 - acc: 0.1029\n",
      "Epoch 00002: val_loss did not improve from 14.19376\n",
      "48000/48000 [==============================] - 18s 377us/sample - loss: 14.4603 - acc: 0.1029 - val_loss: 14.2231 - val_acc: 0.1175\n",
      "Epoch 3/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 14.4754 - acc: 0.1019\n",
      "Epoch 00003: val_loss improved from 14.19376 to 14.18778, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 18s 379us/sample - loss: 14.4761 - acc: 0.1019 - val_loss: 14.1878 - val_acc: 0.1197\n",
      "Epoch 4/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 14.4536 - acc: 0.1033\n",
      "Epoch 00004: val_loss improved from 14.18778 to 14.11811, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 18s 383us/sample - loss: 14.4530 - acc: 0.1033 - val_loss: 14.1181 - val_acc: 0.1240\n",
      "Epoch 5/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 14.4013 - acc: 0.1065\n",
      "Epoch 00005: val_loss did not improve from 14.11811\n",
      "48000/48000 [==============================] - 19s 400us/sample - loss: 14.4032 - acc: 0.1064 - val_loss: 14.1378 - val_acc: 0.1228\n",
      "Epoch 6/10\n",
      "47744/48000 [============================>.] - ETA: 0s - loss: 14.4188 - acc: 0.1054\n",
      "Epoch 00006: val_loss did not improve from 14.11811\n",
      "48000/48000 [==============================] - 20s 407us/sample - loss: 14.4171 - acc: 0.1055 - val_loss: 14.3075 - val_acc: 0.1123\n",
      "Epoch 7/10\n",
      "47744/48000 [============================>.] - ETA: 0s - loss: 14.3943 - acc: 0.1069\n",
      "Epoch 00007: val_loss did not improve from 14.11811\n",
      "48000/48000 [==============================] - 19s 406us/sample - loss: 14.3962 - acc: 0.1068 - val_loss: 14.2699 - val_acc: 0.1147\n",
      "Epoch 8/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 14.4039 - acc: 0.1063\n",
      "Epoch 00008: val_loss improved from 14.11811 to 13.87690, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 20s 410us/sample - loss: 14.4047 - acc: 0.1063 - val_loss: 13.8769 - val_acc: 0.1390\n",
      "Epoch 9/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 14.4321 - acc: 0.1046\n",
      "Epoch 00009: val_loss did not improve from 13.87690\n",
      "48000/48000 [==============================] - 20s 408us/sample - loss: 14.4315 - acc: 0.1046 - val_loss: 14.1920 - val_acc: 0.1195\n",
      "Epoch 10/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 14.3894 - acc: 0.1072\n",
      "Epoch 00010: val_loss improved from 13.87690 to 13.55941, saving model to mnist.model.my_best.hdf5\n",
      "48000/48000 [==============================] - 19s 404us/sample - loss: 14.3894 - acc: 0.1072 - val_loss: 13.5594 - val_acc: 0.1587\n",
      "Test accuracy: 16.3400%\n"
     ]
    }
   ],
   "source": [
    "# reverse the scaling process\n",
    "# rescale [0,1] --> [0,255]\n",
    "X_train = X_train*255\n",
    "X_train = X_train.astype('int32')\n",
    "X_test = X_test*255\n",
    "X_test = X_test.astype('int32')\n",
    "\n",
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=X_train.shape[1:]))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(rate=0.8)) #keep_prob=0.2\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(rate=0.8)) #keep_prob=0.2\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "checkpointer = ModelCheckpoint(filepath='mnist.model.my_best.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "hist = model.fit(X_train, y_train, batch_size=128, epochs=10,\n",
    "          validation_split=0.2, callbacks=[checkpointer],\n",
    "          verbose=1, shuffle=True)\n",
    "\n",
    "# evaluate test accuracy\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "print('Test accuracy: %.4f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model\n",
    "model.load_weights('mnist.model.my_best.hdf5')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
